# ğŸ™ï¸ Realtime AI Meeting Transcript Engine

This project is a **realtime audio-to-text meeting transcription engine** with **async AI enrichment** (refinement + translation).
It is designed as an MVP-quality core for products like **AI meeting assistants**, **live captioning tools**, or **cross-language collaboration apps**.

The system is built to be:

* ğŸ” Realtime-safe (non-blocking)
* ğŸ§  AI-enhanced (LLM-based refinement & translation)
* ğŸ§© Modular & extensible
* âš¡ Low-latency by design

---

## âœ¨ Key Features

* **Realtime audio ingestion**

  * Simulated via `FakeBlackHole` (WAV-based streaming)
  * Ready for system audio tools like BlackHole / Zoom

* **Streaming Speech-to-Text**

  * Sliding windows (2s window / 1s step)
  * Silence-aware segmentation
  * Word-level deduplication
  * Punctuation-aware sentence splitting

* **Async LLM Enrichment**

  * Grammar & clarity refinement
  * Translation to target language
  * Fire-and-forget async calls
  * Order-guaranteed output (no race conditions)

* **Pluggable Output Layer**

  * File-based output (`JSONL`) âœ”ï¸
  * SQLite (planned)
  * WebSocket (planned)

* **Production-grade async lifecycle**

  * No retries (latency-first)
  * Timeout-safe
  * Graceful shutdown with pending task tracking

---

## ğŸ§  Architecture Overview

```text
Audio Stream
    â†“
AudioBufferManager
    â†“
SilenceDetector
    â†“
STT Engine (Whisper)
    â†“
SentenceBuilder
    â†“
RAW Transcript  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Output (immediate)
       â”‚
       â””â”€â”€ Async LLM Enrichment â”€â–¶ OrderedCommitQueue â”€â–¶ Output (delayed)
```

**Key principle:**

> Realtime pipeline is never blocked by AI calls.

---

## ğŸ“‚ Project Structure

```text
.
â”œâ”€â”€ main.py                  # Application entrypoint
â”œâ”€â”€ fake_blackhole.py        # WAV-based audio stream simulator
â”œâ”€â”€ audio_buffer_manager.py  # Sliding window audio buffer
â”œâ”€â”€ silence_detector.py      # Silence detection logic
â”œâ”€â”€ stt_engine.py            # Speech-to-text (Whisper)
â”œâ”€â”€ sentence_builder.py      # Sentence segmentation & cleanup
â”œâ”€â”€ llm_client.py            # Async LLM client
â”œâ”€â”€ llm_commit_queue.py      # Order-guaranteed async commit
â”œâ”€â”€ output_manager.py        # Pluggable output abstraction
â”œâ”€â”€ output/                 # Generated transcripts (ignored by git)
â”œâ”€â”€ audio/                  # Test audio (optional)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Create virtual environment

```bash
python -m venv venv
source venv/bin/activate
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configure environment

Copy example config:

```bash
cp .env.example .env
```

Edit `.env`:

```env
# OpenAI
OPENAI_API_KEY=sk-...

# LLM
LLM_MODEL=gpt-4o-mini
LLM_TARGET_LANG=tr
LLM_TIMEOUT_SEC=3.0

# Output
OUTPUT_FORMAT=FORMAT_FILE
OUTPUT_PATH=output/transcript.jsonl
```

---

## â–¶ï¸ Run

```bash
python main.py
```

Expected behavior:

* RAW transcript sentences are printed immediately
* LLM-refined & translated sentences appear shortly after
* All output is written to `output/transcript.jsonl`

Example output:

```json
{"type":"raw","sentence_id":3,"text":"Who will I be today?","timestamp":...}
{"type":"llm","sentence_id":3,"refined_en":"Who will I be today?","translated":"BugÃ¼n kim olacaÄŸÄ±m?","timestamp":...}
```

---

## ğŸ“¤ Output Formats

Currently supported:

* âœ… `FORMAT_FILE` (JSON Lines)

Planned:

* â³ `FORMAT_SQLITE`
* â³ `FORMAT_WEBSOCKET`

Switching formats does **not** require changing core logic.

---

## ğŸ§ª Design Decisions

* **No retries for LLM calls**
  Latency is prioritized over completeness in realtime scenarios.

* **Order-guaranteed async processing**
  LLM responses may arrive out-of-order; output is always consistent.

* **SentenceBuilder before LLM**
  LLM is used for quality, not structure.

---

## ğŸš€ Possible Extensions

* Live WebSocket UI
* Zoom / system audio integration
* Speaker diarization
* Meeting summaries & action items
* Multi-language input detection
* Cost & latency analytics

---

## ğŸ“Œ Status

âœ… Core MVP complete
ğŸ”§ Actively extensible
ğŸ¯ Ready for productization or portfolio use

---

## ğŸ“„ License

MIT (or your preferred license)
